# UDF Optimizer - Parallel Execution System

Production-ready parallelization system for agent workflows with LLM-based dependency analysis and Gemini API integration.

## ğŸ“ Project Structure

```
udf-optimizer/
â”œâ”€â”€ core/                    # Core system components
â”‚   â”œâ”€â”€ __init__.py         # Package exports
â”‚   â”œâ”€â”€ workflow_types.py   # Data structures (Plan, Step, State, Config)
â”‚   â”œâ”€â”€ nodes.py            # Execution orchestration
â”‚   â”œâ”€â”€ builder.py          # Graph construction
â”‚   â”œâ”€â”€ config_manager.py   # Configuration management
â”‚   â””â”€â”€ gemini_executor.py  # LLM integration (Gemini API)
â”‚
â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ parallel_prompt.md  # LLM system instruction for dependency analysis
â”‚   â””â”€â”€ config.yaml         # Runtime configuration presets
â”‚
â”œâ”€â”€ examples/                # Example files and tests
â”‚   â”œâ”€â”€ example_response_1.txt  # Sample 10-step research plan (JSON)
â”‚   â”œâ”€â”€ example_response.txt    # Alternative example plan
â”‚   â”œâ”€â”€ example_prompt.txt      # Example user prompt
â”‚   â””â”€â”€ test_main.py            # Original Gemini API reference
â”‚
â”œâ”€â”€ tests/                   # Test and validation
â”‚   â””â”€â”€ validate.py         # System validation script
â”‚
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ README.md           # This file (main documentation)
â”‚   â”œâ”€â”€ QUICKSTART.md       # Quick start guide
â”‚   â”œâ”€â”€ REAL_INTEGRATION_GUIDE.md      # Setup and configuration
â”‚   â”œâ”€â”€ REAL_INTEGRATION_SUMMARY.md    # Technical implementation
â”‚   â”œâ”€â”€ TECHNICAL_GUIDE.md             # Architecture details
â”‚   â”œâ”€â”€ IMPLEMENTATION_README.md       # Implementation notes
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md      # Feature summary
â”‚   â”œâ”€â”€ ARCHITECTURE_DIAGRAMS.md       # Visual diagrams
â”‚   â””â”€â”€ CHECKLIST.md                   # Development checklist
â”‚
â”œâ”€â”€ main.py                  # Demo with mock execution
â”œâ”€â”€ main_real.py            # Demo with real Gemini API
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example           # Environment variable template
â”œâ”€â”€ .env                   # Your API key (gitignored)
â””â”€â”€ .gitignore            # Git ignore rules
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure API Key
```bash
# Copy template
cp .env.example .env

# Edit .env and add your key
GEMINI_API_KEY=your_api_key_here
```

Get API key from: https://makersuite.google.com/app/apikey

### 3. Run Validation
```bash
python tests/validate.py
```

### 3. Run the System
```bash
# Real LLM execution (requires API key)
python main_real.py

# Or mock execution (no API key needed)
python main.py

# Run performance comparison (parallel vs sequential)
python compare_performance.py
```

## ğŸ“Š Performance Example

**10-Step Tourist Research Plan:**
- **Sequential**: ~100s (10s per step)
- **Parallel**: ~45s (2.2x speedup)
- **Efficiency**: Automatic LLM-based batching

## ğŸ¯ Key Features

### 1. **LLM-Based Dependency Analysis**
- Automatically determines optimal task batching
- No hardcoded dependency rules
- Conservative parallelization (safe by default)

### 2. **Real Gemini API Integration**
- Dependency analysis using `config/parallel_prompt.md`
- Step execution with context awareness
- Research vs Processing task differentiation

### 3. **Production-Ready Architecture**
- Async/await for non-blocking I/O
- Rate limiting and retry logic
- Comprehensive error handling
- Detailed logging and metrics

### 4. **Flexible Configuration**
```python
from core import Configuration

# Speed preset
config = Configuration.from_preset("speed")

# Custom configuration
config = Configuration(
    max_concurrent_tasks=5,
    task_timeout_seconds=120,
    max_retries=2
)
```

## ğŸ“– Documentation

- **[docs/README.md](docs/README.md)** - Full documentation
- **[docs/QUICKSTART.md](docs/QUICKSTART.md)** - Getting started guide
- **[docs/REAL_INTEGRATION_GUIDE.md](docs/REAL_INTEGRATION_GUIDE.md)** - Setup and troubleshooting
- **[docs/TECHNICAL_GUIDE.md](docs/TECHNICAL_GUIDE.md)** - Architecture deep dive

## ğŸ§ª Testing

### Validation Test
```bash
python tests/validate.py
```
Checks all imports, configurations, and API key setup.

### Mock Execution (Fast)
```bash
python main.py
```
Tests architecture with simulated delays (~4s).

### Real Execution (Realistic)
```bash
python main_real.py
```
Full LLM integration with actual API calls (~45s).

### Performance Comparison
```bash
python compare_performance.py
```
Runs both parallel and sequential execution, captures metrics, and generates an LLM-analyzed performance report to `examples/example_performance_report.md`.

## ğŸ”§ Configuration Presets

| Preset | Concurrent | Timeout | Retries | Use Case |
|--------|-----------|---------|---------|----------|
| **speed** | 5 | 120s | 2 | Development |
| **balanced** | 5 | 120s | 2 | Production |
| **reliability** | 3 | 180s | 3 | Critical |
| **cost** | 2 | 90s | 1 | Budget |

## ğŸ“¦ Core Components

### `core/workflow_types.py`
Data structures: `Plan`, `Step`, `State`, `Configuration`, `StepType`

### `core/nodes.py`
- `parallel_research_team_node()` - Main orchestrator
- `_execute_batch_parallel()` - Concurrent execution
- `_execute_batch_sequential()` - Sequential with context

### `core/gemini_executor.py`
- `DependencyAnalyzer` - LLM-based dependency analysis
- `GeminiStepExecutor` - Step execution with Gemini
- `load_plan_from_json()` - Plan parser

### `core/builder.py`
- `build_parallel_workflow_graph()` - Parallel graph
- `build_sequential_workflow_graph()` - Sequential fallback

### `core/config_manager.py`
- `ConfigurationManager` - YAML config loader
- Preset configurations (speed, balanced, reliability, cost)

## ğŸ› Troubleshooting

### "GEMINI_API_KEY not found"
Create `.env` file with your API key.

### "Rate limit exceeded"
Reduce `max_concurrent_tasks` to 3 or lower.

### "Dependency analysis failed"
Check `config/parallel_prompt.md` exists. System will fallback to heuristic batching.

### "Import errors"
Run `pip install -r requirements.txt` to install dependencies.

## ğŸ’¡ Usage Example

```python
from pathlib import Path
from core import (
    load_plan_from_json,
    parallel_research_team_node,
    State,
    Configuration
)
import asyncio

# Load plan
plan = load_plan_from_json(Path("examples/example_response_1.txt"))

# Create state
state = State(messages=[], observations=[], current_plan=plan)

# Configure
config = Configuration.from_preset("balanced")

# Execute
async def run():
    result = await parallel_research_team_node(state, config)
    return result

asyncio.run(run())
```

## ğŸŒŸ What's New

### v2.0 - Real LLM Integration
- âœ… Gemini 2.0 Flash for dependency analysis
- âœ… Gemini 2.0 Flash for step execution
- âœ… Context-aware prompting
- âœ… Production error handling
- âœ… Organized folder structure

### Architecture Improvements
- âœ… Modular `core/` package
- âœ… Separate `config/`, `examples/`, `tests/`, `docs/`
- âœ… Clean imports with `__init__.py`
- âœ… Relative imports within core modules

## ğŸ“„ Dependencies

```txt
google-generativeai  # Gemini API
python-dotenv        # Environment variables
pyyaml              # Configuration files
```

## ğŸš€ Next Steps

### For Production
1. Add web_search, crawl, python_repl tools
2. Implement streaming responses
3. Add response caching
4. Set up monitoring (Prometheus/Grafana)
5. Add checkpoint system for recovery

### For Experimentation
1. Try different prompting strategies
2. Test various concurrency levels
3. A/B test LLM vs heuristic analysis
4. Benchmark different plans

## ğŸ“ License

See LICENSE file.

## ğŸ™ Credits

Implementation based on "Parallelization Implementation Report for DeerFlow" (2025-11-16).

---

**Status**: âœ… Production Ready | **Version**: 2.0 | **Last Updated**: November 2025
